# CS_4395_Portfolio

Portfolio for CS 4395 Classwork

## Chapter 1: Natural Language Processing
- **Github Portfolio Setup** [Instructions Document](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_github_req.pdf) -- Create a GitHub Portfolio for Class Work 
- **Overview of NLP**: Portfolio Assignment 0 [Instructions Document](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_port_hw1.pdf) -- Write an introduction summarizing historical and current approaches to NLP and reflect on your personal interest in NLP [Assignment Document](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Overview_of_NLP.pdf)
## Chapter 2: Python Basics
- [**Assignment 1: Text Processing with Python**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Component_1.pdf) -- Read in the employee file that has been made in an obsolete system, and process the text to be more standardized, where an object is created for each person, with any needed corrections applied, and display the person's information. To run this prorgram you need the lastest edition of pycharm, prefereably the community edition, as well as the latest update (latest as of the date that this is written) of python, and use the given run functionalities of python to run the program. In addition, you will need to specify the relative path ‘data/data.csv’ in a sysarg and have all of the files in the correct folders/locations alongside having the right parameter in your pycharm configuration. The weakness of using python for text processing is that it can be slower than when compared to other compiled languages including it's execution speed. In addition, due to certain restrictions in how it was designed because of it being dynamically typed, more errors can pop and further testing is required. However on the other hand, the strength of python is that it has built in functions that that assist in text processing such as with it's string objects. In addition to this, python has additions added to it's standard library that deals with most of the common tasks of text processing. What I learned in this homework includes how to create a python pickle. In addition, I learned how to code a python program that uses sysarg. What was a review for included writing a class in python, and coding regular expressions alongside file I/O. [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Homework1.py) 
## Chapter 3: Intro to NLTK
- [**Assignment 3 Exploring NLTK**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Assignment_3_Exploring%20NLTK.pdf) -- Using a python notebook practice using features of NLTK and examine a professional-level NLP API [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Assignment_3_Exploring_NLTK_Homework.pdf)
## chapter 4: Linguistics 101
- (See Chapter 5)
## Chapter 5: Words and Counting
- [**Chapter 5: Word Guess Game**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Chapter_5.pdf) -- Use Python and NLTK features to explore a [text file](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/anat19.txt) and create a word guessing game [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_HW5.py)
## Chapter 6: POS Tagging
- (See Chapter 7)
## Chapter 7: Relationships between words
- [**WordNet**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Ch7_WordNet.pdf) -- Create a python notebook where you will demonstrate basic skills using WordNet and SentiWordNet and learn to identify collocations [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_HW7.pdf)
## Chapter 8: N-gram Models 
- [**Ngrams**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Ch8_N-grams.pdf) -- Create bigram and unigram dictionaries for English, French, and Italian using the [provided training data](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/ngram_files.zip) where the key is the unigram or bigram text and the value is the count of that unigram or bigram in the data. Then for the test data, calculate probabilities for each language and compare against the true labels.  [(Assignment Document part 1)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/HW8_Part1.py) [(Assignment Document part 2)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/HW8_Part2.py) [(Assignment Document Report)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/HW8_Narrative.docx)
## Chapter 9: CFG Grammar 
(See Chapter 12)
## Chapter 10: Syntax and Parsing 
- [**Sentence Parsing**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Ch10_Sentence_Parsing.pdf) -- Hand draw a PSG tree of a sentence, labeling POS with the phrase terms defined and hand draw a dependency parse of the sentence with dependency relations labeled and defined. The SRL parse should have predicates listed, arguments numbered, and modifiers for sentence verbs with a discussion about their relation to each verb. The pros and cons of each parse should be be discusssed. [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/homework10_cs%204395.docx) 
## Chapter 11: Annotated Parses 
(See chapter 10)
## Chapter 12: Finding or Building Corpora 
- [**Finding or Building a Corpus**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio%20Chapter%2012%20-%20Web%20Crawler.pdf) -- Build a corpus through web scraping/building a web crawler [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/hw_12.py) [(Assignment Document Report)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/HW12_Report.docx)
## Chapter 13: Information Extraction 
(see chatbot project)
## Chapter 14: Vector Space Models 
(see chatbot project)
## Chapter 15: Topic Modeling 
(see chatbot project)
## Chapter 16: Semantics 
(see chatbot project)
## Chapter 17: Introduction to Machine Learning 
(see chapter 18)
## Chapter 18: NumPy, pandas, Sckit-Learn, Seaborn 
[**Portfolio: Reading ACL Papers**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395%20acl%20hw.pdf) --a summary document of article from the 2021 ACL Conference [(Assignment Document)](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/cs_4395_ACL_Paper_BZC180000.docx)
## Chapter 19: Converting text to numeric data
(See Chapter 21)
## Chapter 20: Naive Bayes 
(See Chapter 21)
## Chapter 21: Logistic Regression 
[**Portfolio Assignment: Author Attribution**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_Federalist%20Papers.pdf) -- Gain experience with machine learning using sklearn and Experiment with the NLP task author attribution using the given [.csv file](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/federalist.csv) [(Assignment Document)]()
## Chapter 22: Neural Networks 
(see Chatper 23)
## Chapter 23: Deep Learni24: [**Portfolio Assignment: Text Classification**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/Portfolio_Text_Classification.pdf) -- Make a model and graph from Kaggle data with different architectures and embedding apporaches [(Assignment Document)]()
## Chapter 24: Deep Learning Variations 
## Chapter 25: Embeddings 
## Chapter 26: Encoders and Decoders 
## Chatbot Project
[**Chatbot Project Instructions**](https://github.com/LisaBChen/CS_4395_Portfolio/blob/main/4395_chatbot.pdf) --Create a chatbot using NLP technique [(Assignment Code)]()
